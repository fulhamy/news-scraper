import requests
from bs4 import BeautifulSoup
import csv
from datetime import date
import re

today = date.today()
list_var = {"AUDIO:", "IMAGE:", "VIDEO:"}
success_counter = 0

for i in range(0, 300, 2):
    uid = 254246+i
    r1 = requests.get('https://www.abc.net.au/news/'+str(uid))
    if r1.status_code == 200:

        # print(r1)
        coverpage = r1.content
        soup1 = BeautifulSoup(coverpage, 'html.parser')
        coverpage_news = soup1.find(
            'h1', class_='_3mBrr I7ej6 LTJIg _3qPMD _2hFDS _2Od9e _582YK _2eB4R _3Z8IO')
        date_published = soup1.find('time',class_='W-g-R _14nkQ _3BwtN _2eB4R _3qdyT _3fa1F')
        bi_line = soup1.find('span', class_='W-g-R _3XvRm _3BwtN _2eB4R _3qdyT _7kwJ9')
        body = soup1.find_all('p', class_='_1HzXw')

        if ((coverpage_news is not None) and (coverpage_news.get_text().startswith(tuple(list_var))==False)):
            success_counter += 1
            print("Successful:" + str(success_counter))
            print("Total:" + str(i+1))
            headline = coverpage_news.get_text()
            unique_id = uid

            if date_published is not None:
                pub_date = date_published.get_text()

            if bi_line is not None:
                author = bi_line.get_text()
            else: 
                author = ''

            if body is not None:
                body_text = body
            else: 
                body_text = ''

            year = re.findall(r"[0-9]{4}", pub_date)

            with open('/Users/fulhada/Documents/scrape_results/'+year[0] +'.csv', 'a', newline='') as csvfile:
                fieldnames = ['title', 'published_at', 'created_at', 'UID','published_by']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                writer.writerow({'title': headline, 'published_at': pub_date, 'created_at': today, 'UID': uid, 'published_by': author})
